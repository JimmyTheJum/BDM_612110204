{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":1,"outputs":[{"output_type":"stream","text":"/kaggle/input/954471/954471/Train/M/121368482_3314461121964215_543249990768154260_o.jpg\n/kaggle/input/954471/954471/Train/M/121338993_3559428640790674_3898861408853482856_o.jpg\n/kaggle/input/954471/954471/Train/M/121543339_3481304788558895_349846518547631903_n.jpg\n/kaggle/input/954471/954471/Train/M/121335583_2114014788729050_910466790392877863_n.jpg\n/kaggle/input/954471/954471/Train/M/121478814_3277574072359599_3175620794088564281_n.jpg\n/kaggle/input/954471/954471/Train/M/121381660_3348014425282334_9154920501988623614_o.jpg\n/kaggle/input/954471/954471/Train/M/121472960_3362092607235628_5170860563284396140_o.jpg\n/kaggle/input/954471/954471/Train/M/121222913_2888173951406016_2943121663743613328_n.jpg\n/kaggle/input/954471/954471/Train/F/121256709_972711336544125_7929623606048122247_o.jpg\n/kaggle/input/954471/954471/Train/F/121597221_972711616544097_204099069773999800_o.jpg\n/kaggle/input/954471/954471/Train/F/121282643_1739796282838922_3924762867765759060_n.jpg\n/kaggle/input/954471/954471/Train/F/121453866_1739796116172272_6350458709778971249_n.jpg\n/kaggle/input/954471/954471/Train/F/121526847_972713809877211_481376914472549411_o.jpg\n/kaggle/input/954471/954471/Train/F/121465524_1012059792593580_5614978863786312552_o.jpg\n/kaggle/input/954471/954471/Train/F/121460887_1012057685927124_1603928742736483276_o.jpg\n/kaggle/input/954471/954471/Train/F/121469650_1012059645926928_9115015357761950295_o.jpg\n/kaggle/input/954471/954471/Test/M/121558243_3459617724076248_4826110803681428223_n.jpg\n/kaggle/input/954471/954471/Test/M/121623008_2688765031372476_1265210388791973144_n.jpg\n/kaggle/input/954471/954471/Test/M/121218785_2888174644739280_5191976153731649311_n.jpg\n/kaggle/input/954471/954471/Test/M/121160480_3678313258869851_5818106878740531607_o.jpg\n/kaggle/input/954471/954471/Test/F/121638990_1012059519260274_2330212418373086362_o.jpg\n/kaggle/input/954471/954471/Test/F/121711378_1739798592838691_2434137178508018006_n.jpg\n/kaggle/input/954471/954471/Test/F/121297902_1739796202838930_2202079621057532442_n.jpg\n/kaggle/input/954471/954471/Test/F/121558240_972714016543857_6033716185027836421_o.jpg\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"# Load Image "},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"test_dir=\"/kaggle/input/954471/954471/Test\"\ntrain_dir=\"/kaggle/input/954471/954471/Train\"\n\ntrain_dir_f = train_dir + '/F'\ntrain_dir_m = train_dir + '/M'\ntest_dir_f = test_dir + '/F'\ntest_dir_m = test_dir + '/M'","execution_count":2,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('number of f training images - ',len(os.listdir(train_dir_f)))\nprint('number of m training images - ',len(os.listdir(train_dir_m)))\nprint('number of f testing images - ',len(os.listdir(test_dir_f)))\nprint('number of m testing images - ',len(os.listdir(test_dir_m)))","execution_count":3,"outputs":[{"output_type":"stream","text":"number of f training images -  8\nnumber of m training images -  8\nnumber of f testing images -  4\nnumber of m testing images -  4\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"ImageDataGenerator"},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\ndata_generator = ImageDataGenerator(\n        featurewise_center=False,  # set input mean to 0 over the dataset\n        samplewise_center=False,  # set each sample mean to 0\n        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n        samplewise_std_normalization=False,  # divide each input by its std\n        rescale = 1.0/255.0,   # Intensity Normalized\n        zca_whitening=False,  # apply ZCA whitening\n        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n        zoom_range = 0.2, # Randomly zoom image \n        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n        horizontal_flip=False,  # randomly flip images\n        vertical_flip=False,   # randomly flip images\n        validation_split=0.2)","execution_count":4,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"batch_size = 2\nimg_height = 256 \nimg_width  = 256\ntrain_generator = data_generator.flow_from_directory(\n    train_dir,\n    target_size=(img_height, img_width),\n    batch_size=batch_size,\n    class_mode='binary',\n    subset='training') # set as training data\n\nvalidation_generator = data_generator.flow_from_directory(\n    train_dir, # same directory as training data\n    target_size=(img_height, img_width),\n    batch_size=batch_size,\n    class_mode='binary',\n    subset='validation') # set as validation data\n","execution_count":5,"outputs":[{"output_type":"stream","text":"Found 14 images belonging to 2 classes.\nFound 2 images belonging to 2 classes.\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_generator.class_indices","execution_count":6,"outputs":[{"output_type":"execute_result","execution_count":6,"data":{"text/plain":"{'F': 0, 'M': 1}"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Activation\n# preparing the layers in the Convolutional Deep Neural Network\nmodel = Sequential()\nmodel.add(Conv2D(filters = 32, kernel_size = (3, 3), activation = 'relu', input_shape = train_generator.image_shape))\nmodel.add(MaxPooling2D(pool_size = (2, 2)))\nmodel.add(Dropout(rate = 0.3))\nmodel.add(Conv2D(filters = 64, kernel_size = (3, 3), activation = 'relu'))\nmodel.add(MaxPooling2D(pool_size = (2, 2)))\nmodel.add(Dropout(rate = 0.2))\nmodel.add(Conv2D(filters = 126, kernel_size = (3, 3), activation = 'relu'))\nmodel.add(MaxPooling2D(pool_size = (2, 2)))\nmodel.add(Dropout(rate = 0.15))\nmodel.add(Flatten())\nmodel.add(Dense(units = 16, activation = 'relu'))\nmodel.add(Dropout(rate = 0.3))\nmodel.add(Dense(units = 32, activation = 'relu'))\nmodel.add(Dropout(rate = 0.15))\nmodel.add(Dense(units = 64, activation = 'relu'))\nmodel.add(Dropout(rate = 0.1))\nmodel.add(Dense(units = 1, activation = 'sigmoid'))\nmodel.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])","execution_count":7,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fitted_model = model.fit_generator(\n    train_generator,\n    steps_per_epoch = train_generator.samples // batch_size,\n    validation_data = validation_generator, \n    validation_steps = validation_generator.samples // batch_size,\n    epochs = 250)","execution_count":8,"outputs":[{"output_type":"stream","text":"Epoch 1/250\n7/7 [==============================] - 1s 200ms/step - loss: 0.9527 - accuracy: 0.5000 - val_loss: 0.6916 - val_accuracy: 0.5000\nEpoch 2/250\n7/7 [==============================] - 1s 146ms/step - loss: 0.7158 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\nEpoch 3/250\n7/7 [==============================] - 1s 171ms/step - loss: 0.6944 - accuracy: 0.4286 - val_loss: 0.6930 - val_accuracy: 0.5000\nEpoch 4/250\n7/7 [==============================] - 1s 210ms/step - loss: 0.6938 - accuracy: 0.3571 - val_loss: 0.6931 - val_accuracy: 0.5000\nEpoch 5/250\n7/7 [==============================] - 1s 148ms/step - loss: 0.6935 - accuracy: 0.4286 - val_loss: 0.6929 - val_accuracy: 0.5000\nEpoch 6/250\n7/7 [==============================] - 1s 142ms/step - loss: 0.6947 - accuracy: 0.5714 - val_loss: 0.6931 - val_accuracy: 0.5000\nEpoch 7/250\n7/7 [==============================] - 1s 154ms/step - loss: 0.6934 - accuracy: 0.4286 - val_loss: 0.6932 - val_accuracy: 0.5000\nEpoch 8/250\n7/7 [==============================] - 1s 150ms/step - loss: 0.6924 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\nEpoch 9/250\n7/7 [==============================] - 1s 160ms/step - loss: 0.6933 - accuracy: 0.5000 - val_loss: 0.6927 - val_accuracy: 0.5000\nEpoch 10/250\n7/7 [==============================] - 1s 156ms/step - loss: 0.6923 - accuracy: 0.5714 - val_loss: 0.6911 - val_accuracy: 0.5000\nEpoch 11/250\n7/7 [==============================] - 1s 148ms/step - loss: 0.6913 - accuracy: 0.7143 - val_loss: 0.6901 - val_accuracy: 0.5000\nEpoch 12/250\n7/7 [==============================] - 1s 153ms/step - loss: 0.6897 - accuracy: 0.7143 - val_loss: 0.6887 - val_accuracy: 1.0000\nEpoch 13/250\n7/7 [==============================] - 1s 148ms/step - loss: 0.6879 - accuracy: 0.7857 - val_loss: 0.6930 - val_accuracy: 0.5000\nEpoch 14/250\n7/7 [==============================] - 1s 152ms/step - loss: 0.6835 - accuracy: 0.6429 - val_loss: 0.6775 - val_accuracy: 1.0000\nEpoch 15/250\n7/7 [==============================] - 1s 147ms/step - loss: 0.6785 - accuracy: 0.9286 - val_loss: 0.6683 - val_accuracy: 1.0000\nEpoch 16/250\n7/7 [==============================] - 1s 150ms/step - loss: 0.6659 - accuracy: 0.7857 - val_loss: 0.6335 - val_accuracy: 0.5000\nEpoch 17/250\n7/7 [==============================] - 1s 151ms/step - loss: 0.6131 - accuracy: 0.6429 - val_loss: 0.5842 - val_accuracy: 1.0000\nEpoch 18/250\n7/7 [==============================] - 1s 143ms/step - loss: 0.5674 - accuracy: 0.7143 - val_loss: 0.3281 - val_accuracy: 1.0000\nEpoch 19/250\n7/7 [==============================] - 1s 146ms/step - loss: 0.3428 - accuracy: 0.8571 - val_loss: 0.1458 - val_accuracy: 1.0000\nEpoch 20/250\n7/7 [==============================] - 1s 142ms/step - loss: 0.3883 - accuracy: 0.9286 - val_loss: 0.3853 - val_accuracy: 0.5000\nEpoch 21/250\n7/7 [==============================] - 1s 146ms/step - loss: 0.4259 - accuracy: 0.6429 - val_loss: 0.1599 - val_accuracy: 1.0000\nEpoch 22/250\n7/7 [==============================] - 1s 142ms/step - loss: 0.4267 - accuracy: 0.8571 - val_loss: 0.0689 - val_accuracy: 1.0000\nEpoch 23/250\n7/7 [==============================] - 1s 142ms/step - loss: 0.1623 - accuracy: 0.9286 - val_loss: 7.7147e-04 - val_accuracy: 1.0000\nEpoch 24/250\n7/7 [==============================] - 1s 141ms/step - loss: 0.5219 - accuracy: 0.9286 - val_loss: 0.0643 - val_accuracy: 1.0000\nEpoch 25/250\n7/7 [==============================] - 1s 143ms/step - loss: 0.2952 - accuracy: 0.8571 - val_loss: 0.1417 - val_accuracy: 1.0000\nEpoch 26/250\n7/7 [==============================] - 1s 155ms/step - loss: 0.2616 - accuracy: 0.9286 - val_loss: 0.0966 - val_accuracy: 1.0000\nEpoch 27/250\n7/7 [==============================] - 1s 145ms/step - loss: 0.3416 - accuracy: 0.7857 - val_loss: 0.0313 - val_accuracy: 1.0000\nEpoch 28/250\n7/7 [==============================] - 1s 144ms/step - loss: 0.1174 - accuracy: 1.0000 - val_loss: 6.7958e-04 - val_accuracy: 1.0000\nEpoch 29/250\n7/7 [==============================] - 1s 143ms/step - loss: 0.1297 - accuracy: 0.9286 - val_loss: 0.7297 - val_accuracy: 0.5000\nEpoch 30/250\n7/7 [==============================] - 1s 182ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 2.1643e-07 - val_accuracy: 1.0000\nEpoch 31/250\n7/7 [==============================] - 1s 143ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 1.6803e-07 - val_accuracy: 1.0000\nEpoch 32/250\n7/7 [==============================] - 1s 147ms/step - loss: 1.0064 - accuracy: 0.8571 - val_loss: 0.0181 - val_accuracy: 1.0000\nEpoch 33/250\n7/7 [==============================] - 1s 141ms/step - loss: 0.1807 - accuracy: 0.8571 - val_loss: 0.0186 - val_accuracy: 1.0000\nEpoch 34/250\n7/7 [==============================] - 1s 143ms/step - loss: 0.0849 - accuracy: 1.0000 - val_loss: 0.0550 - val_accuracy: 1.0000\nEpoch 35/250\n7/7 [==============================] - 1s 153ms/step - loss: 0.0736 - accuracy: 0.9286 - val_loss: 0.0037 - val_accuracy: 1.0000\nEpoch 36/250\n7/7 [==============================] - 1s 139ms/step - loss: 0.0909 - accuracy: 0.9286 - val_loss: 1.1100e-04 - val_accuracy: 1.0000\nEpoch 37/250\n7/7 [==============================] - 1s 142ms/step - loss: 0.1161 - accuracy: 0.9286 - val_loss: 3.8357e-04 - val_accuracy: 1.0000\nEpoch 38/250\n7/7 [==============================] - 1s 142ms/step - loss: 0.2736 - accuracy: 0.7857 - val_loss: 3.6167e-04 - val_accuracy: 1.0000\nEpoch 39/250\n7/7 [==============================] - 1s 143ms/step - loss: 0.0153 - accuracy: 1.0000 - val_loss: 3.2642e-05 - val_accuracy: 1.0000\nEpoch 40/250\n7/7 [==============================] - 1s 145ms/step - loss: 0.4117 - accuracy: 0.7857 - val_loss: 3.1265e-05 - val_accuracy: 1.0000\nEpoch 41/250\n7/7 [==============================] - 1s 143ms/step - loss: 0.0146 - accuracy: 1.0000 - val_loss: 9.0725e-05 - val_accuracy: 1.0000\nEpoch 42/250\n7/7 [==============================] - 1s 143ms/step - loss: 0.0599 - accuracy: 0.9286 - val_loss: 0.0116 - val_accuracy: 1.0000\nEpoch 43/250\n7/7 [==============================] - 1s 144ms/step - loss: 0.9197 - accuracy: 0.9286 - val_loss: 0.0057 - val_accuracy: 1.0000\nEpoch 44/250\n7/7 [==============================] - 1s 153ms/step - loss: 0.1193 - accuracy: 0.9286 - val_loss: 0.0112 - val_accuracy: 1.0000\nEpoch 45/250\n7/7 [==============================] - 1s 142ms/step - loss: 0.1730 - accuracy: 0.9286 - val_loss: 0.0634 - val_accuracy: 1.0000\nEpoch 46/250\n7/7 [==============================] - 1s 141ms/step - loss: 0.1676 - accuracy: 0.7857 - val_loss: 0.0071 - val_accuracy: 1.0000\nEpoch 47/250\n7/7 [==============================] - 1s 143ms/step - loss: 0.1659 - accuracy: 0.9286 - val_loss: 0.0266 - val_accuracy: 1.0000\nEpoch 48/250\n7/7 [==============================] - 1s 144ms/step - loss: 0.1075 - accuracy: 0.9286 - val_loss: 0.0011 - val_accuracy: 1.0000\nEpoch 49/250\n7/7 [==============================] - 1s 143ms/step - loss: 0.1057 - accuracy: 0.9286 - val_loss: 0.0020 - val_accuracy: 1.0000\nEpoch 50/250\n7/7 [==============================] - 1s 143ms/step - loss: 0.0597 - accuracy: 1.0000 - val_loss: 5.2118e-05 - val_accuracy: 1.0000\nEpoch 51/250\n7/7 [==============================] - 1s 168ms/step - loss: 0.1730 - accuracy: 0.8571 - val_loss: 2.9126e-04 - val_accuracy: 1.0000\nEpoch 52/250\n7/7 [==============================] - 1s 147ms/step - loss: 0.1084 - accuracy: 0.8571 - val_loss: 2.3841e-04 - val_accuracy: 1.0000\nEpoch 53/250\n7/7 [==============================] - 1s 143ms/step - loss: 0.0262 - accuracy: 1.0000 - val_loss: 9.1727e-05 - val_accuracy: 1.0000\nEpoch 54/250\n7/7 [==============================] - 1s 145ms/step - loss: 0.1064 - accuracy: 0.9286 - val_loss: 6.8626e-05 - val_accuracy: 1.0000\nEpoch 55/250\n7/7 [==============================] - 1s 164ms/step - loss: 0.0252 - accuracy: 1.0000 - val_loss: 2.0864e-05 - val_accuracy: 1.0000\nEpoch 56/250\n7/7 [==============================] - 1s 174ms/step - loss: 0.1250 - accuracy: 0.9286 - val_loss: 5.4072e-06 - val_accuracy: 1.0000\nEpoch 57/250\n7/7 [==============================] - 1s 152ms/step - loss: 0.1193 - accuracy: 0.9286 - val_loss: 6.7270e-05 - val_accuracy: 1.0000\nEpoch 58/250\n","name":"stdout"},{"output_type":"stream","text":"7/7 [==============================] - 1s 147ms/step - loss: 0.0548 - accuracy: 0.9286 - val_loss: 9.3720e-05 - val_accuracy: 1.0000\nEpoch 59/250\n7/7 [==============================] - 1s 153ms/step - loss: 0.0593 - accuracy: 0.9286 - val_loss: 4.2982e-05 - val_accuracy: 1.0000\nEpoch 60/250\n7/7 [==============================] - 1s 142ms/step - loss: 0.0216 - accuracy: 1.0000 - val_loss: 6.6809e-05 - val_accuracy: 1.0000\nEpoch 61/250\n7/7 [==============================] - 1s 153ms/step - loss: 0.1896 - accuracy: 0.8571 - val_loss: 2.0429e-06 - val_accuracy: 1.0000\nEpoch 62/250\n7/7 [==============================] - 1s 144ms/step - loss: 0.1335 - accuracy: 0.8571 - val_loss: 2.5585e-04 - val_accuracy: 1.0000\nEpoch 63/250\n7/7 [==============================] - 1s 146ms/step - loss: 0.2485 - accuracy: 0.8571 - val_loss: 9.6199e-04 - val_accuracy: 1.0000\nEpoch 64/250\n7/7 [==============================] - 1s 146ms/step - loss: 0.0732 - accuracy: 0.9286 - val_loss: 3.2134e-04 - val_accuracy: 1.0000\nEpoch 65/250\n7/7 [==============================] - 1s 147ms/step - loss: 0.0910 - accuracy: 0.9286 - val_loss: 3.5529e-04 - val_accuracy: 1.0000\nEpoch 66/250\n7/7 [==============================] - 1s 150ms/step - loss: 0.0425 - accuracy: 1.0000 - val_loss: 1.0163e-05 - val_accuracy: 1.0000\nEpoch 67/250\n7/7 [==============================] - 1s 157ms/step - loss: 0.0821 - accuracy: 1.0000 - val_loss: 4.8036e-04 - val_accuracy: 1.0000\nEpoch 68/250\n7/7 [==============================] - 1s 151ms/step - loss: 1.5293e-04 - accuracy: 1.0000 - val_loss: 3.0852e-05 - val_accuracy: 1.0000\nEpoch 69/250\n7/7 [==============================] - 1s 152ms/step - loss: 0.1293 - accuracy: 0.9286 - val_loss: 1.5231e-08 - val_accuracy: 1.0000\nEpoch 70/250\n7/7 [==============================] - 1s 155ms/step - loss: 0.0931 - accuracy: 1.0000 - val_loss: 1.6456e-06 - val_accuracy: 1.0000\nEpoch 71/250\n7/7 [==============================] - 1s 143ms/step - loss: 0.1607 - accuracy: 0.8571 - val_loss: 5.4181e-07 - val_accuracy: 1.0000\nEpoch 72/250\n7/7 [==============================] - 1s 139ms/step - loss: 0.3230 - accuracy: 0.7857 - val_loss: 1.0726e-04 - val_accuracy: 1.0000\nEpoch 73/250\n7/7 [==============================] - 1s 140ms/step - loss: 0.0786 - accuracy: 1.0000 - val_loss: 4.1040e-06 - val_accuracy: 1.0000\nEpoch 74/250\n7/7 [==============================] - 1s 141ms/step - loss: 0.1225 - accuracy: 0.9286 - val_loss: 9.9794e-08 - val_accuracy: 1.0000\nEpoch 75/250\n7/7 [==============================] - 1s 141ms/step - loss: 0.0645 - accuracy: 0.9286 - val_loss: 2.1960e-05 - val_accuracy: 1.0000\nEpoch 76/250\n7/7 [==============================] - 1s 143ms/step - loss: 0.0487 - accuracy: 1.0000 - val_loss: 5.7794e-08 - val_accuracy: 1.0000\nEpoch 77/250\n7/7 [==============================] - 1s 141ms/step - loss: 0.0735 - accuracy: 0.9286 - val_loss: 1.2827e-08 - val_accuracy: 1.0000\nEpoch 78/250\n7/7 [==============================] - 1s 142ms/step - loss: 0.2076 - accuracy: 0.9286 - val_loss: 7.7727e-06 - val_accuracy: 1.0000\nEpoch 79/250\n7/7 [==============================] - 1s 153ms/step - loss: 0.0258 - accuracy: 1.0000 - val_loss: 2.5655e-06 - val_accuracy: 1.0000\nEpoch 80/250\n7/7 [==============================] - 1s 144ms/step - loss: 0.0126 - accuracy: 1.0000 - val_loss: 4.0650e-04 - val_accuracy: 1.0000\nEpoch 81/250\n7/7 [==============================] - 1s 140ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 1.1344e-05 - val_accuracy: 1.0000\nEpoch 82/250\n7/7 [==============================] - 1s 173ms/step - loss: 0.0227 - accuracy: 1.0000 - val_loss: 7.7289e-07 - val_accuracy: 1.0000\nEpoch 83/250\n7/7 [==============================] - 1s 141ms/step - loss: 0.0992 - accuracy: 0.9286 - val_loss: 5.1286e-04 - val_accuracy: 1.0000\nEpoch 84/250\n7/7 [==============================] - 1s 144ms/step - loss: 0.1010 - accuracy: 1.0000 - val_loss: 1.4503e-04 - val_accuracy: 1.0000\nEpoch 85/250\n7/7 [==============================] - 1s 140ms/step - loss: 0.0781 - accuracy: 1.0000 - val_loss: 1.1728e-05 - val_accuracy: 1.0000\nEpoch 86/250\n7/7 [==============================] - 1s 139ms/step - loss: 0.1657 - accuracy: 0.9286 - val_loss: 8.1691e-07 - val_accuracy: 1.0000\nEpoch 87/250\n7/7 [==============================] - 1s 139ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 2.9718e-05 - val_accuracy: 1.0000\nEpoch 88/250\n7/7 [==============================] - 1s 150ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 3.0696e-05 - val_accuracy: 1.0000\nEpoch 89/250\n7/7 [==============================] - 1s 144ms/step - loss: 0.0628 - accuracy: 1.0000 - val_loss: 7.4066e-07 - val_accuracy: 1.0000\nEpoch 90/250\n7/7 [==============================] - 1s 143ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 2.2944e-07 - val_accuracy: 1.0000\nEpoch 91/250\n7/7 [==============================] - 1s 142ms/step - loss: 0.0473 - accuracy: 1.0000 - val_loss: 3.7780e-06 - val_accuracy: 1.0000\nEpoch 92/250\n7/7 [==============================] - 1s 144ms/step - loss: 0.2181 - accuracy: 0.8571 - val_loss: 9.9410e-06 - val_accuracy: 1.0000\nEpoch 93/250\n7/7 [==============================] - 1s 141ms/step - loss: 0.0215 - accuracy: 1.0000 - val_loss: 4.2852e-05 - val_accuracy: 1.0000\nEpoch 94/250\n7/7 [==============================] - 1s 143ms/step - loss: 0.0934 - accuracy: 1.0000 - val_loss: 3.7439e-05 - val_accuracy: 1.0000\nEpoch 95/250\n7/7 [==============================] - 1s 141ms/step - loss: 4.0676e-04 - accuracy: 1.0000 - val_loss: 3.4632e-06 - val_accuracy: 1.0000\nEpoch 96/250\n7/7 [==============================] - 1s 141ms/step - loss: 0.0440 - accuracy: 1.0000 - val_loss: 5.9397e-06 - val_accuracy: 1.0000\nEpoch 97/250\n7/7 [==============================] - 1s 149ms/step - loss: 0.0503 - accuracy: 1.0000 - val_loss: 7.7087e-04 - val_accuracy: 1.0000\nEpoch 98/250\n7/7 [==============================] - 1s 145ms/step - loss: 0.0580 - accuracy: 1.0000 - val_loss: 2.8267e-06 - val_accuracy: 1.0000\nEpoch 99/250\n7/7 [==============================] - 1s 157ms/step - loss: 0.0445 - accuracy: 1.0000 - val_loss: 8.3631e-05 - val_accuracy: 1.0000\nEpoch 100/250\n7/7 [==============================] - 1s 151ms/step - loss: 0.0599 - accuracy: 1.0000 - val_loss: 6.5085e-06 - val_accuracy: 1.0000\nEpoch 101/250\n7/7 [==============================] - 1s 158ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 2.9655e-07 - val_accuracy: 1.0000\nEpoch 102/250\n7/7 [==============================] - 1s 148ms/step - loss: 0.0467 - accuracy: 1.0000 - val_loss: 1.5551e-05 - val_accuracy: 1.0000\nEpoch 103/250\n7/7 [==============================] - 1s 145ms/step - loss: 0.0246 - accuracy: 1.0000 - val_loss: 1.3929e-07 - val_accuracy: 1.0000\nEpoch 104/250\n7/7 [==============================] - 1s 143ms/step - loss: 2.3180e-04 - accuracy: 1.0000 - val_loss: 6.1532e-08 - val_accuracy: 1.0000\nEpoch 105/250\n7/7 [==============================] - 1s 154ms/step - loss: 0.0291 - accuracy: 1.0000 - val_loss: 2.6416e-08 - val_accuracy: 1.0000\nEpoch 106/250\n7/7 [==============================] - 1s 144ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 4.5608e-07 - val_accuracy: 1.0000\nEpoch 107/250\n7/7 [==============================] - 1s 143ms/step - loss: 0.0447 - accuracy: 1.0000 - val_loss: 9.7545e-08 - val_accuracy: 1.0000\nEpoch 108/250\n7/7 [==============================] - 1s 180ms/step - loss: 0.0450 - accuracy: 1.0000 - val_loss: 1.0373e-09 - val_accuracy: 1.0000\nEpoch 109/250\n7/7 [==============================] - 1s 148ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 6.6768e-07 - val_accuracy: 1.0000\nEpoch 110/250\n7/7 [==============================] - 1s 139ms/step - loss: 1.5264e-04 - accuracy: 1.0000 - val_loss: 1.4600e-10 - val_accuracy: 1.0000\nEpoch 111/250\n7/7 [==============================] - 1s 141ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 2.1040e-08 - val_accuracy: 1.0000\nEpoch 112/250\n7/7 [==============================] - 1s 141ms/step - loss: 0.2092 - accuracy: 0.9286 - val_loss: 3.2976e-06 - val_accuracy: 1.0000\nEpoch 113/250\n7/7 [==============================] - 1s 143ms/step - loss: 0.0449 - accuracy: 1.0000 - val_loss: 2.0363e-06 - val_accuracy: 1.0000\n","name":"stdout"},{"output_type":"stream","text":"Epoch 114/250\n7/7 [==============================] - 1s 142ms/step - loss: 3.0316e-04 - accuracy: 1.0000 - val_loss: 4.0953e-05 - val_accuracy: 1.0000\nEpoch 115/250\n7/7 [==============================] - 1s 146ms/step - loss: 0.0483 - accuracy: 1.0000 - val_loss: 2.0421e-06 - val_accuracy: 1.0000\nEpoch 116/250\n7/7 [==============================] - 1s 144ms/step - loss: 0.1440 - accuracy: 0.9286 - val_loss: 5.3216e-04 - val_accuracy: 1.0000\nEpoch 117/250\n7/7 [==============================] - 1s 144ms/step - loss: 0.0246 - accuracy: 1.0000 - val_loss: 2.6725e-06 - val_accuracy: 1.0000\nEpoch 118/250\n7/7 [==============================] - 1s 140ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 4.2470e-07 - val_accuracy: 1.0000\nEpoch 119/250\n7/7 [==============================] - 1s 142ms/step - loss: 0.0450 - accuracy: 1.0000 - val_loss: 2.4829e-07 - val_accuracy: 1.0000\nEpoch 120/250\n7/7 [==============================] - 1s 143ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 1.3805e-04 - val_accuracy: 1.0000\nEpoch 121/250\n7/7 [==============================] - 1s 141ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 6.0796e-08 - val_accuracy: 1.0000\nEpoch 122/250\n7/7 [==============================] - 1s 142ms/step - loss: 0.0741 - accuracy: 0.9286 - val_loss: 3.8879e-06 - val_accuracy: 1.0000\nEpoch 123/250\n7/7 [==============================] - 1s 141ms/step - loss: 0.0436 - accuracy: 1.0000 - val_loss: 9.2859e-07 - val_accuracy: 1.0000\nEpoch 124/250\n7/7 [==============================] - 1s 151ms/step - loss: 0.0601 - accuracy: 0.9286 - val_loss: 2.1880e-06 - val_accuracy: 1.0000\nEpoch 125/250\n7/7 [==============================] - 1s 144ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.9338e-10 - val_accuracy: 1.0000\nEpoch 126/250\n7/7 [==============================] - 1s 140ms/step - loss: 2.6982e-04 - accuracy: 1.0000 - val_loss: 7.0274e-10 - val_accuracy: 1.0000\nEpoch 127/250\n7/7 [==============================] - 1s 143ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 3.5154e-09 - val_accuracy: 1.0000\nEpoch 128/250\n7/7 [==============================] - 1s 138ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.4217e-08 - val_accuracy: 1.0000\nEpoch 129/250\n7/7 [==============================] - 1s 139ms/step - loss: 4.5588e-04 - accuracy: 1.0000 - val_loss: 5.0092e-07 - val_accuracy: 1.0000\nEpoch 130/250\n7/7 [==============================] - 1s 144ms/step - loss: 6.3808e-05 - accuracy: 1.0000 - val_loss: 1.6447e-09 - val_accuracy: 1.0000\nEpoch 131/250\n7/7 [==============================] - 1s 144ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 1.8314e-12 - val_accuracy: 1.0000\nEpoch 132/250\n7/7 [==============================] - 1s 143ms/step - loss: 0.0410 - accuracy: 1.0000 - val_loss: 8.9367e-10 - val_accuracy: 1.0000\nEpoch 133/250\n7/7 [==============================] - 1s 151ms/step - loss: 3.2857e-07 - accuracy: 1.0000 - val_loss: 6.3535e-12 - val_accuracy: 1.0000\nEpoch 134/250\n7/7 [==============================] - 1s 163ms/step - loss: 0.2559 - accuracy: 0.9286 - val_loss: 5.6163e-05 - val_accuracy: 1.0000\nEpoch 135/250\n7/7 [==============================] - 1s 147ms/step - loss: 0.1534 - accuracy: 0.9286 - val_loss: 0.0034 - val_accuracy: 1.0000\nEpoch 136/250\n7/7 [==============================] - 1s 139ms/step - loss: 0.7364 - accuracy: 0.9286 - val_loss: 3.0165e-04 - val_accuracy: 1.0000\nEpoch 137/250\n7/7 [==============================] - 1s 142ms/step - loss: 0.0809 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 1.0000\nEpoch 138/250\n7/7 [==============================] - 1s 139ms/step - loss: 0.0417 - accuracy: 1.0000 - val_loss: 0.0016 - val_accuracy: 1.0000\nEpoch 139/250\n7/7 [==============================] - 1s 138ms/step - loss: 0.1320 - accuracy: 0.9286 - val_loss: 1.5029e-04 - val_accuracy: 1.0000\nEpoch 140/250\n7/7 [==============================] - 1s 143ms/step - loss: 0.0799 - accuracy: 0.9286 - val_loss: 7.0977e-05 - val_accuracy: 1.0000\nEpoch 141/250\n7/7 [==============================] - 1s 144ms/step - loss: 0.0359 - accuracy: 1.0000 - val_loss: 3.0909e-07 - val_accuracy: 1.0000\nEpoch 142/250\n7/7 [==============================] - 1s 153ms/step - loss: 0.0479 - accuracy: 1.0000 - val_loss: 2.5069e-08 - val_accuracy: 1.0000\nEpoch 143/250\n7/7 [==============================] - 1s 142ms/step - loss: 0.0580 - accuracy: 1.0000 - val_loss: 5.4799e-07 - val_accuracy: 1.0000\nEpoch 144/250\n7/7 [==============================] - 1s 142ms/step - loss: 0.1019 - accuracy: 0.9286 - val_loss: 1.6375e-12 - val_accuracy: 1.0000\nEpoch 145/250\n7/7 [==============================] - 1s 142ms/step - loss: 0.6261 - accuracy: 0.9286 - val_loss: 3.9965e-08 - val_accuracy: 1.0000\nEpoch 146/250\n7/7 [==============================] - 1s 141ms/step - loss: 0.0661 - accuracy: 1.0000 - val_loss: 8.5718e-06 - val_accuracy: 1.0000\nEpoch 147/250\n7/7 [==============================] - 1s 140ms/step - loss: 0.3392 - accuracy: 0.8571 - val_loss: 7.2720e-04 - val_accuracy: 1.0000\nEpoch 148/250\n7/7 [==============================] - 1s 168ms/step - loss: 0.0338 - accuracy: 1.0000 - val_loss: 2.7465e-05 - val_accuracy: 1.0000\nEpoch 149/250\n7/7 [==============================] - 1s 148ms/step - loss: 0.0316 - accuracy: 1.0000 - val_loss: 3.5400e-05 - val_accuracy: 1.0000\nEpoch 150/250\n7/7 [==============================] - 1s 146ms/step - loss: 0.0666 - accuracy: 1.0000 - val_loss: 1.3194e-05 - val_accuracy: 1.0000\nEpoch 151/250\n7/7 [==============================] - 1s 150ms/step - loss: 0.0140 - accuracy: 1.0000 - val_loss: 1.0005e-04 - val_accuracy: 1.0000\nEpoch 152/250\n7/7 [==============================] - 1s 164ms/step - loss: 1.9230e-04 - accuracy: 1.0000 - val_loss: 8.1448e-06 - val_accuracy: 1.0000\nEpoch 153/250\n7/7 [==============================] - 1s 146ms/step - loss: 0.0188 - accuracy: 1.0000 - val_loss: 1.7480e-05 - val_accuracy: 1.0000\nEpoch 154/250\n7/7 [==============================] - 1s 140ms/step - loss: 0.3433 - accuracy: 0.8571 - val_loss: 2.0822e-04 - val_accuracy: 1.0000\nEpoch 155/250\n7/7 [==============================] - 1s 144ms/step - loss: 0.0596 - accuracy: 1.0000 - val_loss: 0.0025 - val_accuracy: 1.0000\nEpoch 156/250\n7/7 [==============================] - 1s 143ms/step - loss: 0.1172 - accuracy: 1.0000 - val_loss: 0.0049 - val_accuracy: 1.0000\nEpoch 157/250\n7/7 [==============================] - 1s 142ms/step - loss: 0.0941 - accuracy: 1.0000 - val_loss: 8.2357e-04 - val_accuracy: 1.0000\nEpoch 158/250\n7/7 [==============================] - 1s 142ms/step - loss: 0.3893 - accuracy: 0.8571 - val_loss: 3.4204e-06 - val_accuracy: 1.0000\nEpoch 159/250\n7/7 [==============================] - 1s 141ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 3.2847e-09 - val_accuracy: 1.0000\nEpoch 160/250\n7/7 [==============================] - 1s 175ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 2.0038e-12 - val_accuracy: 1.0000\nEpoch 161/250\n7/7 [==============================] - 1s 157ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 6.5064e-08 - val_accuracy: 1.0000\nEpoch 162/250\n7/7 [==============================] - 1s 148ms/step - loss: 8.9413e-04 - accuracy: 1.0000 - val_loss: 1.3330e-12 - val_accuracy: 1.0000\nEpoch 163/250\n7/7 [==============================] - 1s 144ms/step - loss: 0.0437 - accuracy: 1.0000 - val_loss: 3.5189e-10 - val_accuracy: 1.0000\nEpoch 164/250\n7/7 [==============================] - 1s 144ms/step - loss: 1.5094 - accuracy: 0.9286 - val_loss: 2.2700e-05 - val_accuracy: 1.0000\nEpoch 165/250\n7/7 [==============================] - 1s 147ms/step - loss: 0.1859 - accuracy: 0.9286 - val_loss: 0.0424 - val_accuracy: 1.0000\nEpoch 166/250\n7/7 [==============================] - 1s 139ms/step - loss: 0.1420 - accuracy: 0.9286 - val_loss: 0.0035 - val_accuracy: 1.0000\nEpoch 167/250\n7/7 [==============================] - 1s 141ms/step - loss: 0.1400 - accuracy: 1.0000 - val_loss: 0.0871 - val_accuracy: 1.0000\nEpoch 168/250\n7/7 [==============================] - 1s 146ms/step - loss: 0.1247 - accuracy: 0.9286 - val_loss: 0.0036 - val_accuracy: 1.0000\nEpoch 169/250\n7/7 [==============================] - 1s 143ms/step - loss: 0.0884 - accuracy: 1.0000 - val_loss: 9.7083e-05 - val_accuracy: 1.0000\n","name":"stdout"},{"output_type":"stream","text":"Epoch 170/250\n7/7 [==============================] - 1s 143ms/step - loss: 0.9151 - accuracy: 0.9286 - val_loss: 2.1096e-05 - val_accuracy: 1.0000\nEpoch 171/250\n7/7 [==============================] - 1s 143ms/step - loss: 0.4169 - accuracy: 0.9286 - val_loss: 0.2467 - val_accuracy: 1.0000\nEpoch 172/250\n7/7 [==============================] - 1s 143ms/step - loss: 2.0438 - accuracy: 0.7143 - val_loss: 3.3551e-14 - val_accuracy: 1.0000\nEpoch 173/250\n7/7 [==============================] - 1s 144ms/step - loss: 0.0896 - accuracy: 0.9286 - val_loss: 4.8678e-04 - val_accuracy: 1.0000\nEpoch 174/250\n7/7 [==============================] - 1s 144ms/step - loss: 0.4263 - accuracy: 0.8571 - val_loss: 0.0084 - val_accuracy: 1.0000\nEpoch 175/250\n7/7 [==============================] - 1s 145ms/step - loss: 0.2172 - accuracy: 0.8571 - val_loss: 3.8560e-04 - val_accuracy: 1.0000\nEpoch 176/250\n7/7 [==============================] - 1s 141ms/step - loss: 0.0557 - accuracy: 1.0000 - val_loss: 1.5663e-06 - val_accuracy: 1.0000\nEpoch 177/250\n7/7 [==============================] - 1s 151ms/step - loss: 0.1273 - accuracy: 0.9286 - val_loss: 3.8438e-06 - val_accuracy: 1.0000\nEpoch 178/250\n7/7 [==============================] - 1s 141ms/step - loss: 0.2587 - accuracy: 0.9286 - val_loss: 1.7543e-10 - val_accuracy: 1.0000\nEpoch 179/250\n7/7 [==============================] - 1s 141ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 3.5456e-10 - val_accuracy: 1.0000\nEpoch 180/250\n7/7 [==============================] - 1s 141ms/step - loss: 9.6962e-05 - accuracy: 1.0000 - val_loss: 2.6590e-11 - val_accuracy: 1.0000\nEpoch 181/250\n7/7 [==============================] - 1s 144ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 7.9849e-11 - val_accuracy: 1.0000\nEpoch 182/250\n7/7 [==============================] - 1s 144ms/step - loss: 3.9438e-04 - accuracy: 1.0000 - val_loss: 2.1105e-16 - val_accuracy: 1.0000\nEpoch 183/250\n7/7 [==============================] - 1s 142ms/step - loss: 0.6449 - accuracy: 0.9286 - val_loss: 4.0849e-09 - val_accuracy: 1.0000\nEpoch 184/250\n7/7 [==============================] - 1s 141ms/step - loss: 5.6085e-07 - accuracy: 1.0000 - val_loss: 2.5134e-10 - val_accuracy: 1.0000\nEpoch 185/250\n7/7 [==============================] - 1s 139ms/step - loss: 1.2912 - accuracy: 0.9286 - val_loss: 7.2052e-10 - val_accuracy: 1.0000\nEpoch 186/250\n7/7 [==============================] - 1s 148ms/step - loss: 0.0346 - accuracy: 1.0000 - val_loss: 1.0311e-04 - val_accuracy: 1.0000\nEpoch 187/250\n7/7 [==============================] - 1s 179ms/step - loss: 0.1987 - accuracy: 0.9286 - val_loss: 5.4266e-09 - val_accuracy: 1.0000\nEpoch 188/250\n7/7 [==============================] - 1s 142ms/step - loss: 0.9885 - accuracy: 0.9286 - val_loss: 1.2467e-06 - val_accuracy: 1.0000\nEpoch 189/250\n7/7 [==============================] - 1s 142ms/step - loss: 0.5770 - accuracy: 0.9286 - val_loss: 1.0863e-07 - val_accuracy: 1.0000\nEpoch 190/250\n7/7 [==============================] - 1s 144ms/step - loss: 0.3064 - accuracy: 0.9286 - val_loss: 1.3930e-04 - val_accuracy: 1.0000\nEpoch 191/250\n7/7 [==============================] - 1s 141ms/step - loss: 0.3547 - accuracy: 0.9286 - val_loss: 1.9022e-09 - val_accuracy: 1.0000\nEpoch 192/250\n7/7 [==============================] - 1s 141ms/step - loss: 0.5878 - accuracy: 0.7857 - val_loss: 1.9539e-09 - val_accuracy: 1.0000\nEpoch 193/250\n7/7 [==============================] - 1s 144ms/step - loss: 0.3226 - accuracy: 0.9286 - val_loss: 8.1900e-11 - val_accuracy: 1.0000\nEpoch 194/250\n7/7 [==============================] - 1s 139ms/step - loss: 7.7589e-04 - accuracy: 1.0000 - val_loss: 8.3655e-12 - val_accuracy: 1.0000\nEpoch 195/250\n7/7 [==============================] - 1s 149ms/step - loss: 0.2433 - accuracy: 0.9286 - val_loss: 5.7842e-06 - val_accuracy: 1.0000\nEpoch 196/250\n7/7 [==============================] - 1s 142ms/step - loss: 0.4337 - accuracy: 0.9286 - val_loss: 4.2031e-06 - val_accuracy: 1.0000\nEpoch 197/250\n7/7 [==============================] - 1s 160ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 3.3660e-08 - val_accuracy: 1.0000\nEpoch 198/250\n7/7 [==============================] - 1s 144ms/step - loss: 0.1070 - accuracy: 0.9286 - val_loss: 7.3876e-05 - val_accuracy: 1.0000\nEpoch 199/250\n7/7 [==============================] - 1s 172ms/step - loss: 1.0260 - accuracy: 0.8571 - val_loss: 1.7104e-04 - val_accuracy: 1.0000\nEpoch 200/250\n7/7 [==============================] - 1s 148ms/step - loss: 0.2038 - accuracy: 0.9286 - val_loss: 1.5298e-06 - val_accuracy: 1.0000\nEpoch 201/250\n7/7 [==============================] - 1s 147ms/step - loss: 0.5486 - accuracy: 0.9286 - val_loss: 4.8291e-04 - val_accuracy: 1.0000\nEpoch 202/250\n7/7 [==============================] - 1s 147ms/step - loss: 0.0253 - accuracy: 1.0000 - val_loss: 6.1594e-04 - val_accuracy: 1.0000\nEpoch 203/250\n7/7 [==============================] - 1s 146ms/step - loss: 0.0397 - accuracy: 1.0000 - val_loss: 1.0403e-05 - val_accuracy: 1.0000\nEpoch 204/250\n7/7 [==============================] - 1s 143ms/step - loss: 0.0881 - accuracy: 0.9286 - val_loss: 2.3128e-04 - val_accuracy: 1.0000\nEpoch 205/250\n7/7 [==============================] - 1s 143ms/step - loss: 0.1183 - accuracy: 0.9286 - val_loss: 2.8776e-05 - val_accuracy: 1.0000\nEpoch 206/250\n7/7 [==============================] - 1s 138ms/step - loss: 0.0843 - accuracy: 0.9286 - val_loss: 1.9158e-04 - val_accuracy: 1.0000\nEpoch 207/250\n7/7 [==============================] - 1s 146ms/step - loss: 0.3451 - accuracy: 0.9286 - val_loss: 7.6031e-04 - val_accuracy: 1.0000\nEpoch 208/250\n7/7 [==============================] - 1s 141ms/step - loss: 0.0504 - accuracy: 1.0000 - val_loss: 1.1905e-04 - val_accuracy: 1.0000\nEpoch 209/250\n7/7 [==============================] - 1s 144ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 3.7879e-06 - val_accuracy: 1.0000\nEpoch 210/250\n7/7 [==============================] - 1s 142ms/step - loss: 0.0422 - accuracy: 1.0000 - val_loss: 3.5472e-05 - val_accuracy: 1.0000\nEpoch 211/250\n7/7 [==============================] - 1s 140ms/step - loss: 0.3179 - accuracy: 0.9286 - val_loss: 1.0074e-04 - val_accuracy: 1.0000\nEpoch 212/250\n7/7 [==============================] - 1s 140ms/step - loss: 0.0162 - accuracy: 1.0000 - val_loss: 8.6843e-04 - val_accuracy: 1.0000\nEpoch 213/250\n7/7 [==============================] - 1s 162ms/step - loss: 0.1661 - accuracy: 0.9286 - val_loss: 0.0042 - val_accuracy: 1.0000\nEpoch 214/250\n7/7 [==============================] - 1s 159ms/step - loss: 0.1072 - accuracy: 0.9286 - val_loss: 1.9995e-04 - val_accuracy: 1.0000\nEpoch 215/250\n7/7 [==============================] - 1s 143ms/step - loss: 8.1040e-04 - accuracy: 1.0000 - val_loss: 2.9354e-05 - val_accuracy: 1.0000\nEpoch 216/250\n7/7 [==============================] - 1s 144ms/step - loss: 6.7671e-04 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 1.0000\nEpoch 217/250\n7/7 [==============================] - 1s 149ms/step - loss: 0.0353 - accuracy: 1.0000 - val_loss: 5.9160e-06 - val_accuracy: 1.0000\nEpoch 218/250\n7/7 [==============================] - 1s 141ms/step - loss: 0.0129 - accuracy: 1.0000 - val_loss: 2.7000e-07 - val_accuracy: 1.0000\nEpoch 219/250\n7/7 [==============================] - 1s 141ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 2.2082e-05 - val_accuracy: 1.0000\nEpoch 220/250\n7/7 [==============================] - 1s 141ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 1.8383e-04 - val_accuracy: 1.0000\nEpoch 221/250\n7/7 [==============================] - 1s 141ms/step - loss: 4.5694e-04 - accuracy: 1.0000 - val_loss: 3.5846e-06 - val_accuracy: 1.0000\nEpoch 222/250\n7/7 [==============================] - 1s 151ms/step - loss: 4.6182e-04 - accuracy: 1.0000 - val_loss: 3.5797e-07 - val_accuracy: 1.0000\nEpoch 223/250\n7/7 [==============================] - 1s 142ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 2.2088e-08 - val_accuracy: 1.0000\nEpoch 224/250\n7/7 [==============================] - 1s 140ms/step - loss: 0.0888 - accuracy: 0.9286 - val_loss: 5.1851e-07 - val_accuracy: 1.0000\nEpoch 225/250\n","name":"stdout"},{"output_type":"stream","text":"7/7 [==============================] - 1s 142ms/step - loss: 2.6918e-07 - accuracy: 1.0000 - val_loss: 1.2177e-07 - val_accuracy: 1.0000\nEpoch 226/250\n7/7 [==============================] - 1s 144ms/step - loss: 2.3753e-05 - accuracy: 1.0000 - val_loss: 3.5286e-08 - val_accuracy: 1.0000\nEpoch 227/250\n7/7 [==============================] - 1s 141ms/step - loss: 1.6074e-05 - accuracy: 1.0000 - val_loss: 1.1219e-07 - val_accuracy: 1.0000\nEpoch 228/250\n7/7 [==============================] - 1s 142ms/step - loss: 2.3280e-07 - accuracy: 1.0000 - val_loss: 3.0297e-09 - val_accuracy: 1.0000\nEpoch 229/250\n7/7 [==============================] - 1s 143ms/step - loss: 0.4013 - accuracy: 0.9286 - val_loss: 2.3536e-06 - val_accuracy: 1.0000\nEpoch 230/250\n7/7 [==============================] - 1s 142ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.0429e-08 - val_accuracy: 1.0000\nEpoch 231/250\n7/7 [==============================] - 1s 151ms/step - loss: 2.9251e-07 - accuracy: 1.0000 - val_loss: 1.0717e-07 - val_accuracy: 1.0000\nEpoch 232/250\n7/7 [==============================] - 1s 142ms/step - loss: 0.1513 - accuracy: 0.9286 - val_loss: 1.1457e-05 - val_accuracy: 1.0000\nEpoch 233/250\n7/7 [==============================] - 1s 143ms/step - loss: 0.0555 - accuracy: 0.9286 - val_loss: 1.8533e-04 - val_accuracy: 1.0000\nEpoch 234/250\n7/7 [==============================] - 1s 142ms/step - loss: 0.0692 - accuracy: 1.0000 - val_loss: 5.0093e-05 - val_accuracy: 1.0000\nEpoch 235/250\n7/7 [==============================] - 1s 145ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0138 - val_accuracy: 1.0000\nEpoch 236/250\n7/7 [==============================] - 1s 141ms/step - loss: 0.1049 - accuracy: 0.9286 - val_loss: 1.5773e-04 - val_accuracy: 1.0000\nEpoch 237/250\n7/7 [==============================] - 1s 139ms/step - loss: 5.3402e-04 - accuracy: 1.0000 - val_loss: 9.2637e-06 - val_accuracy: 1.0000\nEpoch 238/250\n7/7 [==============================] - 1s 145ms/step - loss: 0.0104 - accuracy: 1.0000 - val_loss: 1.8674e-06 - val_accuracy: 1.0000\nEpoch 239/250\n7/7 [==============================] - 1s 145ms/step - loss: 5.6850e-04 - accuracy: 1.0000 - val_loss: 9.1546e-04 - val_accuracy: 1.0000\nEpoch 240/250\n7/7 [==============================] - 1s 188ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 2.3113e-05 - val_accuracy: 1.0000\nEpoch 241/250\n7/7 [==============================] - 1s 145ms/step - loss: 0.0315 - accuracy: 1.0000 - val_loss: 6.8016e-06 - val_accuracy: 1.0000\nEpoch 242/250\n7/7 [==============================] - 1s 140ms/step - loss: 0.1707 - accuracy: 0.9286 - val_loss: 1.5853e-05 - val_accuracy: 1.0000\nEpoch 243/250\n7/7 [==============================] - 1s 142ms/step - loss: 0.1123 - accuracy: 0.9286 - val_loss: 3.6130e-05 - val_accuracy: 1.0000\nEpoch 244/250\n7/7 [==============================] - 1s 143ms/step - loss: 0.0705 - accuracy: 0.9286 - val_loss: 3.8557e-05 - val_accuracy: 1.0000\nEpoch 245/250\n7/7 [==============================] - 1s 164ms/step - loss: 0.0314 - accuracy: 1.0000 - val_loss: 0.0028 - val_accuracy: 1.0000\nEpoch 246/250\n7/7 [==============================] - 1s 145ms/step - loss: 0.0357 - accuracy: 1.0000 - val_loss: 7.3933e-05 - val_accuracy: 1.0000\nEpoch 247/250\n7/7 [==============================] - 1s 140ms/step - loss: 0.0854 - accuracy: 0.9286 - val_loss: 2.0335e-06 - val_accuracy: 1.0000\nEpoch 248/250\n7/7 [==============================] - 1s 141ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 3.0061e-05 - val_accuracy: 1.0000\nEpoch 249/250\n7/7 [==============================] - 1s 163ms/step - loss: 0.0338 - accuracy: 1.0000 - val_loss: 2.8558e-05 - val_accuracy: 1.0000\nEpoch 250/250\n7/7 [==============================] - 1s 157ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 2.1236e-07 - val_accuracy: 1.0000\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.preprocessing import image\n# testing the model\n\ntest_image = image.load_img('../input/954471/954471/Test/F/121558240_972714016543857_6033716185027836421_o.jpg', target_size = (img_height, img_width))\ntest_image = image.img_to_array(test_image)\ntest_image = np.expand_dims(test_image, axis = 0)\nresult = model.predict(test_image)\nprint(np.round(result[0]))","execution_count":9,"outputs":[{"output_type":"stream","text":"[1.]\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.preprocessing import image\n# testing the model\n\ntest_image = image.load_img('../input/954471/954471/Test/M/121160480_3678313258869851_5818106878740531607_o.jpg', target_size = (img_height, img_width))\ntest_image = image.img_to_array(test_image)\ntest_image = np.expand_dims(test_image, axis = 0)\nresult = model.predict(test_image)\nprint(np.round(result[0]))","execution_count":10,"outputs":[{"output_type":"stream","text":"[1.]\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.preprocessing import image\n# testing the model\n\ntest_image = image.load_img('../input/954471/954471/Test/M/121623008_2688765031372476_1265210388791973144_n.jpg', target_size = (img_height, img_width))\ntest_image = image.img_to_array(test_image)\ntest_image = np.expand_dims(test_image, axis = 0)\nresult = model.predict(test_image)\nprint(np.round(result[0]))","execution_count":11,"outputs":[{"output_type":"stream","text":"[1.]\n","name":"stdout"}]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}